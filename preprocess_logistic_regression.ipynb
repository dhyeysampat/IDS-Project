{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "import setuptools\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "load_dotenv()\n",
    "spark = SparkSession.builder.remote(os.getenv('SPARK_HOST')).appName(os.getenv('SPARK_APP_NAME')).getOrCreate()\n",
    "ROOT = os.getenv('WORKING_DIR') or '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(ROOT + 'data/tax_trafi_merged_data')\n",
    "vtax = spark.read.parquet(ROOT + 'data/index_vehicle_tax_data.parquet')\n",
    "prices = spark.read.parquet(ROOT + 'data/knn_imputed_prices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = spark.read.options(encoding=\"ISO-8859-1\", delimiter=\";\", header=True).csv(ROOT + 'data/regions.csv')\n",
    "regions = regions.withColumn('municipality', F.substring('sourceCode', 2, 3))\\\n",
    "    .withColumn('region', F.substring('targetCode', 2, 2))\\\n",
    "    .select('municipality', 'region')\n",
    "regions.show(5)\n",
    "\n",
    "#regions.write.parquet(ROOT + 'data/cleaned_regions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(vtax, on='index').join(prices, on='index')\n",
    "df = df.join(regions, on='municipality', how='left')\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(F.col('vehicle_classification') == 'M1')\\\n",
    "    .withColumn('registration_year', F.year(F.col('date_of_first_registration')))\\\n",
    "    .withColumnRenamed('imputed_price', 'price')\\\n",
    "    .select('index', 'registration_year', 'n_doors', 'n_seats', 'body_type', 'drive_power', 'municipality', 'region', 'vtax', 'price')\n",
    "\n",
    "df.printSchema()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01 gasoline, 04 electricity\n",
    "df = df.filter((F.col('drive_power') == '01') | (F.col('drive_power') == '04'))\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('electric', F.when(F.col('drive_power') == '01', 0).otherwise(1))\\\n",
    "    .drop('drive_power')\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens = spark.read.options(encoding=\"ISO-8859-1\", delimiter=\";\", header=True).csv(ROOT + 'data/001_11ra_2023_20241028-183337.csv').withColumnRenamed('Area', 'name').drop('information')\n",
    "\n",
    "kunta = spark.read.options(encoding=\"UTF-8\", delimiter=\";\", header=True).csv(ROOT + 'data/kunta.csv')\\\n",
    "    .withColumnRenamed('classificationName', 'name').select('code', 'name')\\\n",
    "    .withColumn('code', F.substring('code', 2, 3))\n",
    "kunta.show(5)\n",
    "dens.show(5)\n",
    "\n",
    "d2 = dens.join(kunta, on='name', how='left')\n",
    "d2 = d2.withColumnRenamed('code', 'municipality')\n",
    "d2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType, DoubleType\n",
    "\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\n",
    "fuel = spark.read.options(encoding=\"UTF-8\", delimiter=\";\", header=True).csv(ROOT + 'data/Fuel_prices.csv')\n",
    "\n",
    "fuel.show(5)\n",
    "\n",
    "fuel = np.array(fuel.collect())[:, [0, 8]]\n",
    "\n",
    "fuel = spark.createDataFrame(data=fuel)\n",
    "fuel.show(5)\n",
    "\n",
    "fuel = fuel.withColumn('date', F.to_date('_1', \"yyyy'M'MM\").cast(DateType()))\\\n",
    "    .withColumn('year', F.year('date')).withColumn('month', F.month('date'))\\\n",
    "    .select('year', 'month', '_2').withColumnRenamed('_2', 'fuelCost')\\\n",
    "    .withColumn('fuelCost', F.col('fuelCost').cast(DoubleType()))\n",
    "\n",
    "fuel.show(5)\n",
    "fuel.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuelyear = fuel.groupBy('year').mean('fuelCost').withColumnRenamed('avg(fuelCost)', 'fuelCost').withColumnRenamed('year', 'registration_year')\n",
    "df = df.join(fuelyear, on='registration_year', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity = spark.read.options(encoding=\"ISO-8859-1\", delimiter=\";\", header=True).csv(ROOT + 'data/001_13rb_2024m06_20241028-193343.csv')\n",
    "electricity.show(5)\n",
    "\n",
    "electricity = electricity.withColumn('date', F.to_date('Month', \"yyyy'M'MM\").cast(DateType()))\\\n",
    "    .withColumn('year', F.year('date')).withColumn('month', F.month('date'))\\\n",
    "    .withColumn('cents_kWh', F.col('Price (c/kWh)').cast(DoubleType()))\\\n",
    "    .groupBy('year').avg('cents_kWh').withColumnRenamed('avg(cents_kWh)', 'cents_kWh')\\\n",
    "    .select('year', 'cents_kWh')\n",
    "\n",
    "electricity.show(5)\n",
    "electricity.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "elecyear = electricity.withColumnRenamed('year', 'registration_year')\n",
    "df = df.join(elecyear, on='registration_year', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_csv(ROOT + 'data/001_118w_2022_20241028-200329.csv', sep=';', encoding='latin-1').T\n",
    "#income['info'] = income.index\n",
    "income.reset_index(inplace=True)\n",
    "\n",
    "income['year'] = income['index'].str.slice(0, 4)\n",
    "income['index'] = income['index'].str.slice(5)\n",
    "income = income.drop(0)\n",
    "income.head()\n",
    "\n",
    "income.to_csv(ROOT + 'data/median_income.csv', index=False, sep=';', encoding='latin-1')\n",
    "\n",
    "# hh_med_income = spark.createDataFrame(income)\n",
    "# hh_med_income.show(5)\n",
    "\n",
    "#income['year'] = income['Information'].str.slice(0, 5)\n",
    "#income.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_med_income = spark.read.options(encoding=\"ISO-8859-1\", delimiter=\";\", header=True).csv(ROOT + 'data/median_income.csv')\n",
    "hh_med_income.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_med_income = hh_med_income.withColumnRenamed('0', 'median_hh_income').withColumnRenamed('index', 'name').withColumn('year', F.col('year').cast('int'))\n",
    "hh_med_income.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_med_income = kunta.join(hh_med_income, on='name', how='left')\n",
    "hh_med_income.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_med_income = hh_med_income.withColumnRenamed('code', 'municipality').withColumn('hh_med_income', F.col('median_hh_income').cast('int')).withColumnRenamed('year', 'registration_year').select('municipality', 'registration_year', 'hh_med_income')\n",
    "hh_med_income.show(5)\n",
    "hh_med_income.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(hh_med_income, on=['registration_year', 'municipality'], how='left')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, y in enumerate(range(2010, 2024)):\n",
    "    ydata = d2.select(str(y), 'municipality').withColumnRenamed(str(y), 'population')\n",
    "    result = df.filter(F.col('registration_year') == y)\\\n",
    "        .join(ydata, on='municipality', how='left')\n",
    "    \n",
    "    result.write.mode('overwrite').parquet(ROOT + f'data/preprocessed_regression_data_part_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "un = None\n",
    "\n",
    "for i, y in enumerate(range(2010, 2024)):\n",
    "    if un == None:\n",
    "        un = spark.read.parquet(ROOT + f'data/preprocessed_regression_data_part_{i}')\n",
    "    else:\n",
    "        un = un.union(spark.read.parquet(ROOT + f'data/preprocessed_regression_data_part_{i}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "un.write.mode('overwrite').parquet(ROOT + 'data/preprocessed_regression_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pddf = pd.DataFrame(un.collect(), columns=un.columns)\n",
    "pddf.head()\n",
    "pddf.to_csv(ROOT + './data/regression.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
