{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setuptools\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "load_dotenv()\n",
    "SPARK_HOST = os.getenv('SPARK_HOST')\n",
    "SPARK_APP_NAME = os.getenv('SPARK_APP_NAME')\n",
    "\n",
    "spark = SparkSession.builder.remote(SPARK_HOST).appName(SPARK_APP_NAME).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "\n",
    "ROOT = os.getenv('WORKING_DIR')\n",
    "\n",
    "trafidata = spark.read.parquet(ROOT + 'data/traficom_open_data_for_vehicles')\n",
    "trafidata.show(5)\n",
    "\n",
    "# Add index to traficom data for merging\n",
    "trafidata = trafidata.withColumn('index', F.monotonically_increasing_id())\n",
    "\n",
    "trafidata.write.options(encoding=\"ISO-8859-1\", header=True, delimiter=\";\").parquet(ROOT + 'data/trafidata_with_indices')\n",
    "\n",
    "taxprice = spark.read.parquet(ROOT + 'data/tax_data_with_price_predictions')\n",
    "taxprice.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAFIDATA_ORIG = trafidata\n",
    "TAXPRICE_ORIG = taxprice\n",
    "\n",
    "# Select passanger cars\n",
    "# https://www.traficom.fi/en/transport/road/vehicle-categories\n",
    "\n",
    "trafidata = trafidata.filter(trafidata.vehicle_classification == 'M1')\n",
    "\n",
    "DATA_START_DATE = '2011-01-01'\n",
    "\n",
    "# Filter out old vehicles, match tax data start date\n",
    "#trafidata = trafidata.filter(F.col('date_of_first_registration') >= DATA_START_DATE) \\\n",
    "#    .filter((F.col('date_of_use') >= DATA_START_DATE) | (F.col('date_of_use') == None))\n",
    "\n",
    "# Lowercasing\n",
    "trafidata = trafidata.withColumn('make_plaintext', F.lower(F.col('make_plaintext')))\n",
    "taxprice = taxprice.withColumn('make', F.lower(F.col('make'))).withColumn('model', F.lower(F.col('model'))) \\\n",
    "\n",
    "# date is first registration or date of use, whichever is not null\n",
    "taxprice = taxprice.withColumn('date', F.coalesce(F.col('date_of_first_registration'), F.col('date_of_use')))\n",
    "\n",
    "# # add columns for traficom matched make and model\n",
    "# taxprice = taxprice.withColumn('matched_make', F.lit(None).cast('string'))\\\n",
    "#     .withColumn('matched_model', F.lit(None).cast('string'))\\\n",
    "#     .withColumn('matched_trade_name', F.lit(None).cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafidata = trafidata.select('make_plaintext', 'model', 'manufac_trade_name',  'date_of_first_registration',\n",
    "    'date_of_use', 'n_doors', 'drive_power', 'max_net_engine_power_kw', 'transmission', 'odometer', 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ROOT + 'data/temp'\n",
    "options = {'encoding':\"ISO-8859-1\", 'delimiter':\";\", 'header': True}\n",
    "\n",
    "try:\n",
    "    hammeasure = taxprice.select('index', 'make', 'model').write.options(**options).parquet(path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "hammeasure = pd.read_parquet(path)\n",
    "hammeasure.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import jellyfish\n",
    "\n",
    "unique_makers = sorted([x[0] for x in trafidata.filter(F.col('make_plaintext').isNotNull()).select('make_plaintext').distinct().collect()])\n",
    "\n",
    "manufacdata = dict()\n",
    "modeldata = dict()\n",
    "\n",
    "def get_col_unique_given_make(make, col):\n",
    "    if col == 'manufac_trade_name':\n",
    "        ret = manufacdata.get(make, None)\n",
    "    elif col == 'model':\n",
    "        ret = modeldata.get(make, None)\n",
    "    \n",
    "    if ret is None:\n",
    "        ret = trafidata.filter((F.col('make_plaintext') == make) & (F.col(col).isNotNull())).select(F.lower(col)).distinct().collect()\n",
    "    \n",
    "    ret = [x[0] for x in ret]\n",
    "\n",
    "    if col == 'manufac_trade_name':\n",
    "        manufacdata[make] = ret\n",
    "    elif col == 'model':\n",
    "        modeldata[make] = ret\n",
    "\n",
    "    return ret\n",
    "\n",
    "# Match make and model\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(hammeasure.shape[0])):\n",
    "    row = hammeasure.iloc[i, :]\n",
    "\n",
    "    make = row['make']\n",
    "    model = row['model']\n",
    "    index = int(row['index'])\n",
    "\n",
    "    # Find best matching make\n",
    "    makedist = np.array([jellyfish.levenshtein_distance(make, x) for x in unique_makers])\n",
    "    make0 = unique_makers[np.argmin(makedist)]\n",
    "\n",
    "    # Find best matching manufacturer trade name given the best matching make\n",
    "#    options = get_col_unique_given_make(make0, 'manufac_trade_name')\n",
    "\n",
    "    # if len(options) > 0:\n",
    "    #     tradedist = np.array([jellyfish.levenshtein_distance(make, x) for x in options])\n",
    "    #     tradename0 = options[np.argmin(tradedist)]\n",
    "    # else:\n",
    "    #     tradename0 = None\n",
    "\n",
    "    # # Find best matching model name\n",
    "    # options = get_col_unique_given_make(make0, 'model')\n",
    "\n",
    "    # if len(options) > 0:\n",
    "    #     modeldist = np.array([jellyfish.levenshtein_distance(make, x) for x in options])\n",
    "    #     model0 = options[np.argmin(modeldist)]\n",
    "    # else:\n",
    "    #     model0 = None\n",
    "\n",
    "    #results.append([index, make0, model0, tradename0])\n",
    "    results.append([index, make0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, LongType\n",
    "\n",
    "df = pd.DataFrame.from_dict({\n",
    "    'index': [x[0] for x in results],\n",
    "    'matched_make_plaintext': [x[1] for x in results],\n",
    "    # 'matched_model': [x[2] for x in results],\n",
    "    # 'matched_manufac_trade_name': [x[3] for x in results]\n",
    "})\n",
    "\n",
    "df.head(50)\n",
    "\n",
    "df = spark.createDataFrame(df)\n",
    "\n",
    "makesprices = taxprice.join(df, on='index')\n",
    "\n",
    "makesprices = makesprices.orderBy(F.rand())\n",
    "\n",
    "makesprices.show(5)\n",
    "\n",
    "tax_indices = makesprices.select('index').collect()\n",
    "tax_indices = [x['index'] for x in tax_indices]\n",
    "\n",
    "\n",
    "#print(tax_indices[:5])\n",
    "\n",
    "# matched_data = spark.createDataFrame(df)\n",
    "\n",
    "# matched_data.show(5)\n",
    "\n",
    "# pd.DataFrame([indices, makes, models, tradenames], columns= ['index', ])\n",
    "\n",
    "# # add columns for traficom matched make and model\n",
    "# taxprice = taxprice.withColumn('matched_make', F.lit(None).cast('string'))\\\n",
    "#     .withColumn('matched_model', F.lit(None).cast('string'))\\\n",
    "#     .withColumn('matched_trade_name', F.lit(None).cast('string'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "dou = 'date_of_use'\n",
    "dofr = 'date_of_first_registration'\n",
    "\n",
    "matches = []\n",
    "used = set()\n",
    "\n",
    "# trafidata = trafidata.select('n_doors', 'drive_power', 'max_net_engine_power_kw', 'transmission', 'odometer', 'index')\n",
    "\n",
    "# Define distance function\n",
    "def distance(tax, trafi, datecol):\n",
    "    # Model\n",
    "    if tax['model'] != None and  trafi['model'] != None:\n",
    "        modeld = jellyfish.levenshtein_distance(tax['model'], trafi['model'])\n",
    "        modeld = modeld / (1 + modeld) # map to [0, 1]\n",
    "    else:\n",
    "        modeld = np.inf\n",
    "\n",
    "    # Date\n",
    "    dated = abs((tax[datecol] - trafi[datecol]).days) # 0 or 1\n",
    "\n",
    "    # Doors\n",
    "    if tax['n_doors'] != None and trafi['n_doors'] != None:\n",
    "        doord = 0 if trafi['n_doors'] == tax['n_doors'] else np.inf\n",
    "    else:\n",
    "        doord = 1\n",
    "\n",
    "    # Odometer\n",
    "    if tax['odometer_unit_1000km'] != None and trafi['odometer'] != None:\n",
    "        odod = abs(trafi['odometer'] * 1000 - tax['odometer_unit_1000km']) \n",
    "        odod = odod / (1 + odod) # map to [0, 1]\n",
    "    else:\n",
    "        odod = 1\n",
    "\n",
    "    return modeld + dated + doord + odod\n",
    "\n",
    "makesprices1 = makesprices.select('index', 'matched_make_plaintext', 'date_of_use', 'date_of_first_registration',\n",
    "    'model', 'odometer_unit_1000km', 'driving_power', 'n_doors', 'Kw', 'transmission', 'body_style', 'drivetrain').collect()\n",
    "trafidata1 = trafidata.orderBy('date_of_first_registration').persist(StorageLevel.MEMORY_ONLY)\n",
    "trafidata2 = trafidata.orderBy('date_of_use').persist(StorageLevel.MEMORY_ONLY)\n",
    "\n",
    "# Iterate through all entries by key in random order\n",
    "\n",
    "for i in tqdm(range(len(makesprices1))):\n",
    "    result = makesprices1[i]\n",
    "\n",
    "    if result[dou] == None:\n",
    "        datecol = dofr\n",
    "        date = result[dofr]\n",
    "        datasrc = trafidata2\n",
    "    else:\n",
    "        datecol = dou\n",
    "        date = result[dou]\n",
    "        datasrc = trafidata1\n",
    "\n",
    "    candidates = datasrc.filter((F.col(datecol) >= date - timedelta(days=1)) & (F.col(datecol) <= date + timedelta(days=1))).filter(F.col('make_plaintext') == result['matched_make_plaintext'])\\\n",
    "        .select('date_of_first_registration', 'date_of_use', 'model', 'odometer', 'drive_power', 'n_doors', 'max_net_engine_power_kw', 'transmission', 'index').collect()\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        continue\n",
    "\n",
    "    candidates = [x for x in candidates if x['index'] not in used]\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        continue\n",
    "\n",
    "    distances = [distance(result, x, datecol) for x in candidates]\n",
    "    pair = candidates[np.argmin(distances)]\n",
    "    matches.append((result['index'], pair['index']))\n",
    "    used.add(pair['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchesdf = spark.createDataFrame(matches, ['tax_index', 'trafi_index'])\n",
    "matchesdf.write.options(encoding=\"ISO-8859-1\", header=True, delimiter=\";\").parquet(ROOT + 'data/tax_trafi_index_pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafidata = TRAFIDATA_ORIG\n",
    "taxprice = TAXPRICE_ORIG\n",
    "\n",
    "matches = matchesdf.withColumnRenamed('tax_index', 'index')\n",
    "taxprice = taxprice.join(matches, on='index').withColumnRenamed('index', 'tax_index').withColumnRenamed('trafi_index', 'index')\n",
    "trafidata = trafidata.join(taxprice, on='index')\n",
    "trafidata.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# dates = trafidata.select('date_of_first_registration').distinct().orderBy(F.col('date_of_first_registration'), ascending=False).collect()\n",
    "# dates = [x[0] for x in dates]\n",
    "# distincts = np.zeros(len(dates))\n",
    "\n",
    "# merged = None\n",
    "\n",
    "# for i, date in enumerate(dates[365:365+10]):\n",
    "#     traf = trafidata.filter(F.col('date_of_first_registration') == date).groupBy('make_plaintext').count().select('make_plaintext', 'count').collect()\n",
    "#     tax = taxprice.filter(F.col('date_of_first_registration') == date).groupBy('make').count().select('make', 'count').collect()\n",
    "\n",
    "#     trafcounts = dict([(x[0], x[1]) for x in traf ])\n",
    "#     taxcounts = dict([(x[0], x[1]) for x in tax ])\n",
    "#     mergeable = []\n",
    "\n",
    "#     for k, v in taxcounts.items():\n",
    "#         if k not in trafcounts:\n",
    "#             del trafcounts[k]\n",
    "\n",
    "#         if v == 1 and trafcounts.get(k, None) == 1:\n",
    "#             mergeable.append(k)\n",
    "\n",
    "#     print(date)\n",
    "#     print(f'tra {trafcounts}')\n",
    "#     print(f'tax {taxcounts}')\n",
    "#     print(mergeable)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
